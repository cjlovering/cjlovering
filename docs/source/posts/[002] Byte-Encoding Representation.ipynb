{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Byte-Encoding Representation\n",
    "\n",
    "This is a subword tokenization of a vocabulary. An example of this from Sennrich et al. is as follows:\n",
    "\n",
    "> vocab = ‘low’, ‘lowest’, ‘newer’, ‘wider’\n",
    "\n",
    "> OOV = 'lower' --> 'low_', 'er_'\n",
    "\n",
    "This is much more valuable than a UNK symbol. To build this representation, an iterative algorithm can be used to link together the most common segments, starting with character pairs. Below is the pseudo code provided by the original authors with a few changes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('e', 'r')\n",
      "('er', '</w>')\n",
      "('l', 'o')\n",
      "('lo', 'w')\n",
      "('low', '</w>')\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import sys\n",
    "import collections\n",
    "\n",
    "def get_stats(vocab):\n",
    "    \"\"\"For the given merge step, get the bigram counts, for every pair of symbols (strings).\n",
    "\n",
    "    For each word and its freq in the corpus, add the number of instances for each of its subword parts.\n",
    "    \"\"\"\n",
    "    pairs = collections.defaultdict(int)\n",
    "    for word, freq in vocab.items():\n",
    "        symbols = word.split()\n",
    "        for i in range(len(symbols)-1):\n",
    "            pairs[symbols[i],symbols[i+1]] += freq\n",
    "    return pairs\n",
    "\n",
    "def merge_vocab(pair, v_in):\n",
    "    v_out = {}\n",
    "    bigram_pattern = re.escape(' '.join(pair))\n",
    "    p = re.compile(r'(?<!\\S)' + bigram_pattern + r'(?!\\S)')\n",
    "    for word in v_in:\n",
    "        w_out = p.sub(''.join(pair), word)\n",
    "        v_out[w_out] = v_in[word]\n",
    "    return v_out\n",
    "\n",
    "vocab = {\n",
    "  'l o w </w>' : 5, \n",
    "  'f a r t h e s t </w>' : 5,\n",
    "  'n e w e r </w>': 5,\n",
    "  'w i d e r </w>': 5 }\n",
    "num_merges = 5\n",
    "transforms = set()\n",
    "for i in range(num_merges):\n",
    "    pairs = get_stats(vocab)\n",
    "\n",
    "    try:\n",
    "        best = max(pairs, key=pairs.get)\n",
    "    except ValueError:\n",
    "        break\n",
    "    if pairs[best] < 2:\n",
    "        print('no pair has frequency > 1. Stopping\\n')\n",
    "        break\n",
    "    transforms.add(best)\n",
    "    vocab = merge_vocab(best, vocab)\n",
    "    print(best)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
