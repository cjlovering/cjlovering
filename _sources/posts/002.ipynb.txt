{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Beam Search\n",
    "\n",
    "Beam search is a method for decoding a sequence, and it is often used translation. In the main, beam search is used at test time, not during training. The algorithm is also described in this [paper](https://arxiv.org/pdf/1409.3215v1.pdf%3B). For a full implementation see [OpenNMT](https://github.com/OpenNMT/OpenNMT-py/blob/master/onmt/translate/beam.py), otherwise I provide an instructive implementation below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given a function $f$, which takes a sequence and outputs a probability distribution of output symbols for the next item in the sequence, beam-search is an approximate algorithm which searches for the path that results in the most probable sequence. The path with the highest probability to start with, may not end up being the most likely sequence.\n",
    "\n",
    "For example, if there were 3 possible symbols to output (A, B, C), and given a start symbol the first output is [0.90, 0.05, 0.05]. However, if in the next time step, the probability for all the sequences that start with A are all equal, [0.33, 0.33, 0.33], and the probabilities if we had selected B or C are much higher [0.,0.,0.99] for many steps, we would have preferred to select another path. Note that often the scores we use are in the log space to avoid floating point issues with small probabilities.\n",
    "\n",
    "If one used depth-first search, each path would be evaluated, but at exponential cost. For example, with a vocabulary of 3 possible output symbols, and a maximum length of 10 symbols, finding the most likely path would cost $3^{10}$ operations. Beam search instead does not maintain all possibilities. Instead it keeps the current best-so-far $h$ possibilties. This instead requires a linear number of operations (around 30 in this example.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import heapq\n",
    "from collections import namedtuple\n",
    "Beam = namedtuple('Beam', ['ys', 'log_prob_seq'])\n",
    "\n",
    "def beam_search_decode(model, src, src_mask, max_len, start_symbol, beam_count=3):\n",
    "    \"\"\"Basic beam search decode function. (Untested).\n",
    "    \"\"\"\n",
    "    memory = model.encode(src, src_mask)\n",
    "    candidates = [ Beam(torch.ones(1, 1).fill_(start_symbol).type_as(src.data), 0) ]\n",
    "    # generate a word up to the max length. the system could represent stop symbols to stop early.\n",
    "    for i in range(max_len-1):\n",
    "        # for each path, operate on that path (autoregressive).\n",
    "        outputs = [\n",
    "            model.decode(\n",
    "                memory, \n",
    "                src_mask,\n",
    "                Variable(c.ys),\n",
    "                Variable(subsequent_mask(c.ys.size(1)).type_as(src.data)))\n",
    "            for c in candidates\n",
    "        ]\n",
    "        # select the most probable words\n",
    "        results = []\n",
    "        for out in outputs:\n",
    "            # generate a probability distribution over the possible output symbols.\n",
    "            dist = model.generator(out[:, -1])\n",
    "            # look at the top beam_count possibilities in each path.\n",
    "            for _ in range(beam_count):\n",
    "                prob, next_word = torch.max(dist, dim = 1)\n",
    "                log_prob = torch.log(prob)\n",
    "                next_word = next_word.data[0]\n",
    "                dist[next_word] = -1e9 # zero out.\n",
    "                ys = torch.cat([output.ys, torch.ones(1, 1).type_as(src.data).fill_(next_word)], dim=1)\n",
    "                log_prob_seq = output.log_prob_seq + log_prob\n",
    "                results.append(Beam(ys, log_prob_seq))\n",
    "        candidates = heapq.nlargest(beam_count, results, key=lambda b: b.log_prob_seq)\n",
    "    return ys"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
